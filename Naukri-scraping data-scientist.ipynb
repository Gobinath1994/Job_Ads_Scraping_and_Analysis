{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T12:40:29.676972Z",
     "start_time": "2020-04-25T12:40:29.668986Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T08:14:07.429024Z",
     "start_time": "2020-04-25T08:14:07.425037Z"
    }
   },
   "outputs": [],
   "source": [
    "header={'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing selenium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T12:59:24.923903Z",
     "start_time": "2020-04-25T12:59:19.496945Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'webdriver_manager'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-418f3b7d2f90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'--incognito'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'--headless'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwebdriver_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchrome\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mChromeDriverManager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'chromedriver.exe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'webdriver_manager'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--headless')\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(executable_path='chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T14:29:11.719563Z",
     "start_time": "2020-04-25T14:29:11.714577Z"
    }
   },
   "source": [
    "## scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T13:04:29.725145Z",
     "start_time": "2020-04-25T13:00:34.995578Z"
    }
   },
   "outputs": [],
   "source": [
    "Link=[]\n",
    "for page in range(1,100):#first 50 pages of the naukri search\n",
    "    driver.get(\"https://www.naukri.com/data-scientist-jobs-in-india?k=%22data%20scientist%22&l=india-\"+str(page))\n",
    "    timeDelay = random.randrange(0, 20)\n",
    "    time.sleep(timeDelay)\n",
    "    soup=BeautifulSoup(driver.page_source, 'lxml')#returns html of the page\n",
    "    for i in soup.findAll(attrs={'class':\"jobTuple bgWhite br4 mb-8\"}):\n",
    "        for j in i.findAll(attrs={'class':\"title fw500 ellipsis\"}):\n",
    "            Link.append(j.get('href')) #stores all the link of the job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T13:04:29.864949Z",
     "start_time": "2020-04-25T13:04:29.856960Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(Link) #total link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T13:54:36.016197Z",
     "start_time": "2020-04-25T13:15:32.911735Z"
    }
   },
   "outputs": [],
   "source": [
    "salary=[]\n",
    "experience=[]\n",
    "Location=[]\n",
    "description=[]\n",
    "role=[]\n",
    "industry_type=[]\n",
    "qualification=[]\n",
    "Functional_area=[]\n",
    "Employment_type=[]\n",
    "Role_category=[]\n",
    "company=[]\n",
    "skills=[]\n",
    "\n",
    "\n",
    "\n",
    "for lin in range(len(Link)):\n",
    "    driver.get(Link[lin])\n",
    "    #time.sleep(1)\n",
    "    soup=BeautifulSoup(driver.page_source, 'lxml') \n",
    "    if soup.find(attrs={'class':\"salary\"})==None: #to skip the error\n",
    "        continue\n",
    "    else:\n",
    "\n",
    "        experience.append(soup.find(attrs={'class':\"exp\"}).text)\n",
    "        salary.append(soup.find(attrs={'class':\"salary\"}).text)\n",
    "        Location.append(soup.find(attrs={'class':'loc'}).find('a').text)\n",
    "\n",
    "        \n",
    "        description.append(soup.find(attrs={'class':\"job-desc\"}).text)\n",
    "            \n",
    "\n",
    "        details=[]\n",
    "\n",
    "        for i in soup.find(attrs={'class':\"other-details\"}).findAll(attrs={'class':\"details\"}):\n",
    "            details.append(i.text)\n",
    "        \n",
    "        role.append(details[0])\n",
    "        industry_type.append(details[1])\n",
    "\n",
    "        Functional_area.append(details[2])\n",
    "        Employment_type.append(details[3])\n",
    "        Role_category.append(details[4])\n",
    "\n",
    "        qual=[]\n",
    "        for i in soup.find(attrs={'class':\"education\"}).findAll(attrs={'class':'details'}):\n",
    "            qual.append(i.text)\n",
    "        qualification.append(qual)\n",
    "      \n",
    "\n",
    "        company.append(soup.find(attrs={'class':\"about-company\"}).find(attrs={'class':\"detail dang-inner-html\"}).text)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T13:54:36.353271Z",
     "start_time": "2020-04-25T13:54:36.345293Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T13:54:36.641504Z",
     "start_time": "2020-04-25T13:54:36.601605Z"
    }
   },
   "outputs": [],
   "source": [
    "df['company']=company\n",
    "df['role']=role\n",
    "df['salary']=salary\n",
    "df['experience']=experience\n",
    "df['Location']=Location\n",
    "df['description']=description\n",
    "df['qualification']=qualification\n",
    "df['industry_type']=industry_type\n",
    "\n",
    "df['Functional_area']=Functional_area\n",
    "df['Employment_type']=Employment_type\n",
    "df['Role_category']=Role_category\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T13:58:46.614503Z",
     "start_time": "2020-04-25T13:58:46.606524Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T13:59:14.738771Z",
     "start_time": "2020-04-25T13:59:14.720819Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T13:59:46.039702Z",
     "start_time": "2020-04-25T13:59:45.854475Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('naukri_data-scientist.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-25T14:02:53.358600Z",
     "start_time": "2020-04-25T14:02:53.229742Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
